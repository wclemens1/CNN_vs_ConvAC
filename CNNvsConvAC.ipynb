{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of CNN and ConvAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While reading around the subject of deep learning I started to look for links between the field and AdS/CFT, my field of study for my PhD. Among other attempts to make this connection I found https://arxiv.org/abs/1704.01552 which posits a relation between the tensor networks used in condensed matter physics and \"ConvACs\" a variation on convolutional neural networks with linear activations and nonlinearity introduced by product pooling that the authors had previously introduced in https://arxiv.org/abs/1509.05009.\n",
    "\n",
    "In order to understand this technique better, mostly so I can judge the plausibility of the connection to physics, I decided to implement a simple ConvAC and compare it's performance to an equivalent CNN on a simple problem: the MINST dataset.\n",
    "\n",
    "It should be noted that the papers in question are very theoretical and this notebook comprises my messing around to try and understand them rather than an attempt to replicate a specific result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense , Dropout, Lambda, Flatten, Conv2D, MaxPool2D, Input, AveragePooling2D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "assert K.image_data_format() == \"channels_last\"\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "X_train = np.reshape(X_train, (-1, 28, 28, 1))/255\n",
    "X_test = np.reshape(X_test, (-1, 28, 28, 1))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willc\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:653: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (60000, 28, 28, 1) (1 channels).\n",
      "  ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                             samplewise_center=False,  # set each sample mean to 0\n",
    "                             featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                             samplewise_std_normalization=False,  # divide each input by its std\n",
    "                             zca_whitening=False,  # apply ZCA whitening\n",
    "                             rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                             zoom_range = 0.1, # Randomly zoom image \n",
    "                             width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                             height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                             horizontal_flip=False,  # randomly flip images\n",
    "                             vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a very small model so it trains in a reasonable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_img = Input(shape = (28, 28, 1))\n",
    "\n",
    "X1 = Conv2D(32, (3, 3), activation = \"relu\", padding = \"same\")(input_img)\n",
    "X1 = MaxPool2D(pool_size = (2, 2))(X1)\n",
    "X1 = Dropout(0.25)(X1)\n",
    "\n",
    "X1 = Conv2D(64, (3, 3), activation = \"relu\", padding = \"same\")(X1)\n",
    "X1 = MaxPool2D(pool_size = (2, 2))(X1)\n",
    "X1 = Dropout(0.25)(X1)\n",
    "\n",
    "X1 = Flatten()(X1)\n",
    "X1 = Dense(256, activation = \"relu\")(X1)\n",
    "X1 = Dropout(0.5)(X1)\n",
    "CNN_output = Dense(10, activation = \"softmax\")(X1)\n",
    "\n",
    "CNN_model = Model(input_img, CNN_output)\n",
    "CNN_model.compile(optimizer = optimizer,\n",
    "                  loss = \"categorical_crossentropy\",\n",
    "                  metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "697/697 [==============================] - 114s - loss: 0.4282 - acc: 0.8622   \n",
      "Epoch 2/3\n",
      "697/697 [==============================] - 117s - loss: 0.1736 - acc: 0.9476   \n",
      "Epoch 3/3\n",
      "697/697 [==============================] - 116s - loss: 0.1396 - acc: 0.9582   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x256fff61208>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 3\n",
    "batch_size = 86\n",
    "\n",
    "CNN_model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                        epochs = epochs,\n",
    "                        verbose = 1,\n",
    "                        steps_per_epoch = X_train.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A product pooling layer is just an average pooling layer multiplied by the pool size. Obviously this gives us a hint at which model will give better performance in the end..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = Conv2D(32, (3, 3), padding = \"same\")(input_img)\n",
    "X2 = AveragePooling2D(pool_size = (2, 2))(X2)\n",
    "X2 = Lambda(lambda x: 2*2*x)(X2)\n",
    "X2 = Dropout(0.25)(X2)\n",
    "\n",
    "X2 = Conv2D(64, (3, 3), padding = \"same\")(X2)\n",
    "X2 = AveragePooling2D(pool_size = (2, 2))(X2)\n",
    "X2 = Lambda(lambda x: 2*2*x)(X2)\n",
    "X2 = Dropout(0.25)(X2)\n",
    "\n",
    "X2 = Flatten()(X2)\n",
    "X2 = Dense(256, activation = \"relu\")(X2)\n",
    "X2 = Dropout(0.5)(X2)\n",
    "ConvAC_output = Dense(10, activation = \"softmax\")(X2)\n",
    "\n",
    "ConvAC_model = Model(input_img, ConvAC_output)\n",
    "ConvAC_model.compile(optimizer = optimizer,\n",
    "                     loss = \"categorical_crossentropy\",\n",
    "                     metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "697/697 [==============================] - 105s - loss: 0.7434 - acc: 0.7694   \n",
      "Epoch 2/3\n",
      "697/697 [==============================] - 116s - loss: 0.4755 - acc: 0.8572   \n",
      "Epoch 3/3\n",
      "697/697 [==============================] - 112s - loss: 0.4254 - acc: 0.8723   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25680fde710>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvAC_model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                        epochs = epochs,\n",
    "                        verbose = 1,\n",
    "                        steps_per_epoch = X_train.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the winner is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.030486235922342165, 0.99199999999999999]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model.evaluate(x = X_test, y = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12419580230116845, 0.96240000000000003]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvAC_model.evaluate(x = X_test, y = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN! Well that was unsurprising. We already know that max pooling performs better than average pooling. Still a hands on implementation was informative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
